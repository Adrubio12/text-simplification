{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5axfdjOyE3Y"
      },
      "outputs": [],
      "source": [
        "!pip install ohmeow-blurr -q\n",
        "!pip install bert-score -q\n",
        "!pip install sacremoses\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import *\n",
        "from fastai.text.all import *\n",
        "from blurr.text.data.all import *\n",
        "from blurr.text.modeling.all import *\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcwvflAfyST8"
      },
      "outputs": [],
      "source": [
        "#Get data\n",
        "df = pd.read_csv('/content/datos_modifiedComa.csv', error_bad_lines=False, sep=',')\n",
        "df = df[['snt_id','source_snt','simplified_snt']]\n",
        "\n",
        "articles = df.head(638)\n",
        "\n",
        "\n",
        "n_labels = len(articles[\"source_snt\"].unique())\n",
        "print(n_labels)\n",
        "articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6EqLXgH2pw9"
      },
      "outputs": [],
      "source": [
        "#Import model\n",
        "pretrained_model_name = \"facebook/bart-large-cnn\"\n",
        "hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=BartForConditionalGeneration)\n",
        "\n",
        "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M64BCfqi3JpX"
      },
      "outputs": [],
      "source": [
        "text_gen_kwargs = {}\n",
        "if hf_arch in [\"bart\", \"t5\"]:\n",
        "    text_gen_kwargs = {**hf_config.task_specific_params[\"summarization\"], **{\"max_length\": 50, \"min_length\": 10}}\n",
        "\n",
        "# not all \"summarization\" parameters are for the model.generate method ... remove them here\n",
        "generate_func_args = list(inspect.signature(hf_model.generate).parameters.keys())\n",
        "for k in text_gen_kwargs.copy():\n",
        "    if k not in generate_func_args:\n",
        "        del text_gen_kwargs[k]\n",
        "\n",
        "if hf_arch == \"mbart\":\n",
        "    text_gen_kwargs[\"decoder_start_token_id\"] = hf_tokenizer.get_vocab()[\"en_XX\"]\n",
        "    \n",
        "tok_kwargs = {}\n",
        "if hf_arch == \"mbart\":\n",
        "    tok_kwargs[\"src_lang\"], tok_kwargs[\"tgt_lang\"] = \"en_XX\", \"en_XX\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOAi2qMD21pG"
      },
      "outputs": [],
      "source": [
        "batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n",
        "    hf_arch,\n",
        "    hf_config,\n",
        "    hf_tokenizer,\n",
        "    hf_model,\n",
        "    max_length=256,\n",
        "    max_target_length=130,\n",
        "    tok_kwargs=tok_kwargs,\n",
        "    text_gen_kwargs=text_gen_kwargs,\n",
        ")\n",
        "\n",
        "blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
        "\n",
        "dblock = DataBlock(blocks=blocks, get_x=ColReader(\"source_snt\"), get_y=ColReader(\"simplified_snt\"), splitter=RandomSplitter())\n",
        "dls = dblock.dataloaders(articles, bs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-LX7Bf23Yp1"
      },
      "outputs": [],
      "source": [
        "dls.show_batch(dataloaders=dls, max_n=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IZs28cD3i70"
      },
      "outputs": [],
      "source": [
        "seq2seq_metrics = {\n",
        "    \"rouge\": {\n",
        "        \"compute_kwargs\": {\"rouge_types\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"], \"use_stemmer\": True},\n",
        "        \"returns\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],\n",
        "    },\n",
        "    \"bertscore\": {\"compute_kwargs\": {\"lang\": \"en\"}, \"returns\": [\"precision\", \"recall\", \"f1\"]},\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoJkBusU3mNz"
      },
      "outputs": [],
      "source": [
        "model = BaseModelWrapper(hf_model)\n",
        "learn_cbs = [BaseModelCallback]\n",
        "fit_cbs = [Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n",
        "\n",
        "learn = Learner(\n",
        "    dls,\n",
        "    model,\n",
        "    opt_func=partial(Adam),\n",
        "    loss_func=CrossEntropyLossFlat(),\n",
        "    cbs=learn_cbs,\n",
        "    splitter=partial(blurr_seq2seq_splitter, arch=hf_arch),\n",
        ")\n",
        "\n",
        "# learn = learn.to_native_fp16() #.to_fp16()\n",
        "learn.freeze()\n",
        "#learn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVIgkNLD306l"
      },
      "outputs": [],
      "source": [
        "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qn5z4lL04JRq"
      },
      "outputs": [],
      "source": [
        "learn.fit_one_cycle(5, lr_max=3.311311302240938e-05, cbs=fit_cbs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_Wh8PP-5gNO"
      },
      "outputs": [],
      "source": [
        "learn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=250)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ens32Jnn_72"
      },
      "outputs": [],
      "source": [
        "#Use test data to generate simplifications\n",
        "df = pd.read_csv('/content/simpletext_task3_test.csv',  sep=',')\n",
        "df['simplified_snt'] = \" \"\n",
        "#modify run id for different runs\n",
        "df['run_id'] = 'HULAT-UC3M11'\n",
        "#the generation of the simplifications has been automatic\n",
        "df['manual'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQyFqsPvVxaP"
      },
      "outputs": [],
      "source": [
        "#the model cannot process all 100.000+ entries of the test data in one go, a subset of the test data must be chosen to be executed\n",
        "#it doesnt have to strictly be the head of the dataframe, for example rows 2000-3999 could be chosen\n",
        "df = df.head(100)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nd9BUKE9kUUT"
      },
      "outputs": [],
      "source": [
        "pip install swifter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHdvriOkkaGX"
      },
      "outputs": [],
      "source": [
        "import swifter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKxZSZVQqAYb"
      },
      "outputs": [],
      "source": [
        "#generate simplifications\n",
        "def simplify (snt):\n",
        "  output = learn.blurr_generate(snt, num_return_sequences=1)\n",
        "  final = output[0]['generated_texts']\n",
        "  return(final)\n",
        "\n",
        "\n",
        "df['simplified_snt'] = df.swifter.apply(lambda row: simplify(row['source_snt']),axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRkT-ZxG_KNz"
      },
      "outputs": [],
      "source": [
        "df = df[['run_id','manual','snt_id','simplified_snt']]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoPXXpPtZX_U"
      },
      "outputs": [],
      "source": [
        "df.to_csv('runA.csv', index=False,sep ='\\t')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "text_simplification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}